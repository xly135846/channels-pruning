{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd816751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 14:23:52.371222: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from kerassurgeon import identify\n",
    "from kerassurgeon.operations import delete_channels\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "from model_res import mobilenet_res\n",
    "\n",
    "random.seed(2021)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c82dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_from_filenames(file_path):\n",
    "    with open(file_path,'r',) as f:\n",
    "        lines = [one_line.strip('\\n') for one_line in f.readlines()]\n",
    "    return lines\n",
    "\n",
    "### conv1+conv2 conv3+conv4 \n",
    "### conv5+conv6 conv7+conv8\n",
    "layers_name = ['conv_1', \n",
    "               'conv_2',\n",
    "               'conv_3',\n",
    "               'conv_4',\n",
    "               'conv_5',\n",
    "               'conv_6',\n",
    "               'conv_7',\n",
    "               'conv_8',\n",
    "               'block_8_conv_1',\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f9019cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 14:23:53.857890: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-18 14:23:53.968537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:84:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.635GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-01-18 14:23:53.968583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-18 14:23:53.971050: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-18 14:23:53.973183: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-18 14:23:53.973527: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-18 14:23:53.976105: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-18 14:23:53.977295: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-18 14:23:53.982191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-18 14:23:53.985052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2022-01-18 14:23:53.985751: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-18 14:23:53.997509: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2099985000 Hz\n",
      "2022-01-18 14:23:54.000898: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560cca8a9890 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-18 14:23:54.000939: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-01-18 14:23:54.298155: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560ccc6c7be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-01-18 14:23:54.298214: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2022-01-18 14:23:54.306758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:84:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.635GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-01-18 14:23:54.306827: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-18 14:23:54.306886: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-18 14:23:54.306925: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-18 14:23:54.306962: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-18 14:23:54.306999: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-18 14:23:54.307035: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-18 14:23:54.307074: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-18 14:23:54.315453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2022-01-18 14:23:54.315525: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-18 14:23:54.929436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-18 14:23:54.929479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2022-01-18 14:23:54.929488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2022-01-18 14:23:54.932566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10070 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:84:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100, 100, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 50, 50, 12)   120         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 50, 50, 12)   48          conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 50, 50, 12)   156         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 50, 50, 12)   48          conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 50, 50, 12)] 0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 25, 25, 24)   2616        tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 25, 25, 24)   96          conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 25, 25, 24)   600         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 25, 25, 24)   96          conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 25, 25, 24)] 0           batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 13, 13, 36)   7812        tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 13, 13, 36)   144         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 13, 13, 36)   1332        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 13, 13, 36)   144         conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, 13, 13, 36)] 0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 7, 7, 48)     15600       tf_op_layer_AddV2_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 48)     192         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 7, 7, 48)     2352        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 7, 7, 48)     192         conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_3 (TensorFlow [(None, 7, 7, 48)]   0           batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_8_conv_1 (Conv2D)         (None, 7, 7, 128)    6272        tf_op_layer_AddV2_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 128)    0           block_8_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_conv_2 (Conv2D)         (None, 1, 1, 4)      516         average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze (TensorFlow [(None, 4)]          0           block_8_conv_2[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 38,336\n",
      "Trainable params: 37,856\n",
      "Non-trainable params: 480\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = mobilenet_res(channels=[12,12,24,24,36,36,48,48,128])\n",
    "model.load_weights(\"./checkpoints/tmp_res/cp-0005.hdf5\")\n",
    "print(model.summary())\n",
    "\n",
    "batch_size = 256\n",
    "num_epochs = 5\n",
    "initial_learning_rate = 0.001\n",
    "\n",
    "checkpoint_path = \"./checkpoints/tmp_vgg_pruning/cp-{epoch:04d}.hdf5\"\n",
    "LOG_DIR = \"./checkpoints/tmp_vgg_pruning_fitlogs/\"\n",
    "\n",
    "train_image_arr = np.load(\"./val_list_image_array.npy\")\n",
    "train_label_arr = np.load(\"./val_list_one_hot.npy\")\n",
    "\n",
    "val_image_arr = np.load(\"./val_list_image_array.npy\")\n",
    "val_label_arr = np.load(\"./val_list_one_hot.npy\")\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_image_arr, train_label_arr))\n",
    "val_dataset   = tf.data.Dataset.from_tensor_slices((val_image_arr, val_label_arr))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=20000)\n",
    "# train_dataset = train_dataset.repeat(2)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_dataset   = val_dataset.batch(batch_size)\n",
    "val_dataset   = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6af463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ conv_1 ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 14:23:57.010312: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-18 14:23:58.554832: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---mask--- [2] -------\n",
      "------ conv_2 ------\n",
      "---mask--- [ 5 10] -------\n",
      "------ conv_3 ------\n",
      "---mask--- [2 6 7 8] -------\n",
      "------ conv_4 ------\n",
      "---mask--- [ 3  8  9 17 21] -------\n",
      "------ conv_5 ------\n",
      "---mask--- [ 1  3 11 17 22 24 27 30 32] -------\n",
      "------ conv_6 ------\n",
      "---mask--- [ 0  1 17 24 27 29 35] -------\n",
      "------ conv_7 ------\n",
      "---mask--- [ 8 16 19 20 27 29 31 32 34 39] -------\n",
      "------ conv_8 ------\n",
      "---mask--- [ 0  4  8  9 10 12 21 27 42 43 44 46] -------\n",
      "------ block_8_conv_1 ------\n",
      "---mask--- [  1   4   9  11  21  23  32  33  36  42  46  50  51  53  65  69  71  74\n",
      "  76  79  93  97 105 107 108 110 122 127] -------\n"
     ]
    }
   ],
   "source": [
    "all_mask = []    \n",
    "for i in range(len(layers_name)):\n",
    "    print('------',layers_name[i],'------')\n",
    "    layer_conv = model.get_layer(name=layers_name[i])\n",
    "    apoz_layer_conv = identify.get_apoz(model, layer_conv, train_image_arr)\n",
    "    high_apoz_channels_conv = identify.high_apoz(apoz_layer_conv, \"both\")\n",
    "    print(\"---mask---\", high_apoz_channels_conv,\"-------\")\n",
    "    all_mask.append(high_apoz_channels_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06971e59",
   "metadata": {},
   "source": [
    "### 手动选择需要删除的通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d1ea90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_2 = [5,10]\n",
    "conv3_4 = [3,8,9,17,21]\n",
    "conv5_6 = [0,1,17,24,27,29,35]\n",
    "conv7_8 = [0,4,8,9,10,12,21,27,42,43,44,46]\n",
    "block_8_conv_1 = [1,4,9,11,21,23,32,33,36,42,46,50,51,53,65,69,71,74,76,79,93,97,105,107,108,110,122,127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8d3fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_2_mask = [i for i in range(12) if i not in conv1_2]\n",
    "conv3_4_mask = [i for i in range(24) if i not in conv3_4]\n",
    "conv5_6_mask = [i for i in range(36) if i not in conv5_6]\n",
    "conv7_8_mask = [i for i in range(48) if i not in conv7_8]\n",
    "block_8_conv_1_mask = [i for i in range(128) if i not in block_8_conv_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b86400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_weight = model.get_weights()\n",
    "origin_layers = model.layers\n",
    "new_weights = origin_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db3fba1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 1, 12)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(1, 1, 12, 12)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(3, 3, 12, 24)\n",
      "(24,)\n",
      "(24,)\n",
      "(24,)\n",
      "(24,)\n",
      "(24,)\n",
      "(1, 1, 24, 24)\n",
      "(24,)\n",
      "(24,)\n",
      "(24,)\n",
      "(24,)\n",
      "(24,)\n",
      "(3, 3, 24, 36)\n",
      "(36,)\n",
      "(36,)\n",
      "(36,)\n",
      "(36,)\n",
      "(36,)\n",
      "(1, 1, 36, 36)\n",
      "(36,)\n",
      "(36,)\n",
      "(36,)\n",
      "(36,)\n",
      "(36,)\n",
      "(3, 3, 36, 48)\n",
      "(48,)\n",
      "(48,)\n",
      "(48,)\n",
      "(48,)\n",
      "(48,)\n",
      "(1, 1, 48, 48)\n",
      "(48,)\n",
      "(48,)\n",
      "(48,)\n",
      "(48,)\n",
      "(48,)\n",
      "(1, 1, 48, 128)\n",
      "(128,)\n",
      "(1, 1, 128, 4)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(origin_weight)):\n",
    "    print(origin_weight[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a6921d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change(current_shape, j, new_weights, origin_weight, i, conv1_2_mask, num=12):\n",
    "    if (current_shape[j]==num and j==0) or (current_shape[j]==num and j==1):\n",
    "        new_weights[i] = origin_weight[i][conv1_2_mask]\n",
    "    if current_shape[j]==num and j==2:\n",
    "        new_weights[i] = origin_weight[i][:,:,conv1_2_mask,:]\n",
    "    if current_shape[j]==num and j==3:\n",
    "        new_weights[i] = origin_weight[i][:,:,:,conv1_2_mask]\n",
    "    \n",
    "for i in range(len(origin_weight)):\n",
    "    current_shape = new_weights[i].shape\n",
    "    for j in range(len(current_shape)):\n",
    "        change(current_shape, j, new_weights, origin_weight, i, conv1_2_mask, 12)\n",
    "        change(current_shape, j, new_weights, origin_weight, i, conv3_4_mask, 24)\n",
    "        change(current_shape, j, new_weights, origin_weight, i, conv5_6_mask, 36)\n",
    "        change(current_shape, j, new_weights, origin_weight, i, conv7_8_mask, 48)\n",
    "        change(current_shape, j, new_weights, origin_weight, i, block_8_conv_1_mask, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e49f082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_21\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 100, 100, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 50, 50, 10)   100         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 50, 50, 10)   40          conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 50, 50, 10)   110         batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 50, 50, 10)   40          conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_4 (TensorFlow [(None, 50, 50, 10)] 0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 25, 25, 19)   1729        tf_op_layer_AddV2_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 19)   76          conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 25, 25, 19)   380         batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 19)   76          conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_5 (TensorFlow [(None, 25, 25, 19)] 0           batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 13, 13, 29)   4988        tf_op_layer_AddV2_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 13, 13, 29)   116         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 13, 13, 29)   870         batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 13, 13, 29)   116         conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_6 (TensorFlow [(None, 13, 13, 29)] 0           batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 7, 7, 36)     9432        tf_op_layer_AddV2_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 7, 7, 36)     144         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 7, 7, 36)     1332        batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 7, 7, 36)     144         conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_7 (TensorFlow [(None, 7, 7, 36)]   0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_conv_1 (Conv2D)         (None, 7, 7, 100)    3700        tf_op_layer_AddV2_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 100)    0           block_8_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_conv_2 (Conv2D)         (None, 1, 1, 4)      404         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Squeeze_1 (TensorFl [(None, 4)]          0           block_8_conv_2[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 23,797\n",
      "Trainable params: 23,421\n",
      "Non-trainable params: 376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = mobilenet_res(channels=[10,10,19,19,29,29,36,36,100])\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7771576",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a227ba19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 13:57:37.947025: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2022-01-18 13:57:37.947107: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 1/41 [..............................] - ETA: 0s - loss: 0.8581 - accuracy: 0.9102WARNING:tensorflow:From /mnt/fu04/xueluoyang/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 13:57:40.944482: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n",
      "2022-01-18 13:57:40.944576: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\n",
      "WARNING:tensorflow:From /mnt/fu04/xueluoyang/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/41 [>.............................] - ETA: 1s - loss: 0.6503 - accuracy: 0.9277WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0129s vs `on_train_batch_end` time: 0.0399s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-18 13:57:40.970947: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:223]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2022-01-18 13:57:40.975672: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: ./checkpoints/tmp_vgg_pruning_fitlogs/train/plugins/profile/2022_01_18_13_57_40\n",
      "2022-01-18 13:57:40.977000: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to ./checkpoints/tmp_vgg_pruning_fitlogs/train/plugins/profile/2022_01_18_13_57_40/fu04-SYS-4028GR-TR.trace.json.gz\n",
      "2022-01-18 13:57:40.991073: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: ./checkpoints/tmp_vgg_pruning_fitlogs/train/plugins/profile/2022_01_18_13_57_40\n",
      "2022-01-18 13:57:40.994459: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to ./checkpoints/tmp_vgg_pruning_fitlogs/train/plugins/profile/2022_01_18_13_57_40/fu04-SYS-4028GR-TR.memory_profile.json.gz\n",
      "2022-01-18 13:57:40.994955: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: ./checkpoints/tmp_vgg_pruning_fitlogs/train/plugins/profile/2022_01_18_13_57_40Dumped tool data for xplane.pb to ./checkpoints/tmp_vgg_pruning_fitlogs/train/plugins/profile/2022_01_18_13_57_40/fu04-SYS-4028GR-TR.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./checkpoints/tmp_vgg_pruning_fitlogs/train/plugins/profile/2022_01_18_13_57_40/fu04-SYS-4028GR-TR.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./checkpoints/tmp_vgg_pruning_fitlogs/train/plugins/profile/2022_01_18_13_57_40/fu04-SYS-4028GR-TR.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./checkpoints/tmp_vgg_pruning_fitlogs/train/plugins/profile/2022_01_18_13_57_40/fu04-SYS-4028GR-TR.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./checkpoints/tmp_vgg_pruning_fitlogs/train/plugins/profile/2022_01_18_13_57_40/fu04-SYS-4028GR-TR.kernel_stats.pb\n",
      "\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0129s vs `on_train_batch_end` time: 0.0399s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.5845 - accuracy: 0.9124\n",
      "Epoch 00001: saving model to ./checkpoints/tmp_vgg_pruning/cp-0001.hdf5\n",
      "41/41 [==============================] - 3s 63ms/step - loss: 0.5845 - accuracy: 0.9124 - val_loss: 0.8090 - val_accuracy: 0.9125\n",
      "Epoch 2/5\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.9125\n",
      "Epoch 00002: saving model to ./checkpoints/tmp_vgg_pruning/cp-0002.hdf5\n",
      "41/41 [==============================] - 2s 53ms/step - loss: 0.4657 - accuracy: 0.9125 - val_loss: 0.7152 - val_accuracy: 0.9125\n",
      "Epoch 3/5\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4627 - accuracy: 0.9125\n",
      "Epoch 00003: saving model to ./checkpoints/tmp_vgg_pruning/cp-0003.hdf5\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.4627 - accuracy: 0.9125 - val_loss: 0.7132 - val_accuracy: 0.9125\n",
      "Epoch 4/5\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4593 - accuracy: 0.9125\n",
      "Epoch 00004: saving model to ./checkpoints/tmp_vgg_pruning/cp-0004.hdf5\n",
      "41/41 [==============================] - 2s 49ms/step - loss: 0.4593 - accuracy: 0.9125 - val_loss: 0.6972 - val_accuracy: 0.9125\n",
      "Epoch 5/5\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.9125\n",
      "Epoch 00005: saving model to ./checkpoints/tmp_vgg_pruning/cp-0005.hdf5\n",
      "41/41 [==============================] - 2s 52ms/step - loss: 0.4540 - accuracy: 0.9125 - val_loss: 0.6466 - val_accuracy: 0.9125\n"
     ]
    }
   ],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,\n",
    "                                                            decay_steps=15,\n",
    "                                                            decay_rate=0.95,\n",
    "                                                            staircase=True\n",
    "                                                            )\n",
    "\n",
    "new_model.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=initial_learning_rate),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                  save_weights_only=True,\n",
    "                                                  verbose=1,\n",
    "                                                  )\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "\n",
    "HISTORY = new_model.fit(train_dataset, \n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=[checkpointer, reduce_lr, tensorboard_callback],\n",
    "                    shuffle=True,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb7eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
